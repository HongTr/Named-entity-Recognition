{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive, import libraries"
      ],
      "metadata": {
        "id": "p91ygBk6kvEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvqW18aQCSbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9274f557-ef65-4322-b50c-e21a7e081acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/AI\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/AI'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSu2z-rGQPzT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etclMUJrjZPt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "import torch.autograd as autograd\n",
        "torch.manual_seed(1)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #'cuda:0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n1glilH6T02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbcdf9b-40a4-4b57-ad75-4e97ce24a47c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.10)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.9.8)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvi\n",
        "from pyvi import ViPosTagger"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install conlleval\n",
        "from conlleval import evaluate"
      ],
      "metadata": {
        "id": "b4wvOXmExGdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323bf00d-433c-4fa8-f76f-de891dd1f22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: conlleval in /usr/local/lib/python3.7/dist-packages (0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smGFqkdxBGBJ"
      },
      "source": [
        "# Read Pretrained data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNE08vnAgzbn"
      },
      "outputs": [],
      "source": [
        "pretrain_data_0 = pd.read_csv('pretrained100.txt', sep=\" \",header = None, skiprows = 1, nrows = 100000)\n",
        "pretrain_data_1 = pd.read_csv('pretrained100.txt', sep=\" \",header = None, skiprows = 100001, nrows = 100000)\n",
        "pretrain_data_2 = pd.read_csv('pretrained100.txt', sep=\" \",header = None, skiprows = 200001, nrows = 100000)\n",
        "pretrain_data_3 = pd.read_csv('pretrained100.txt', sep=\" \",header = None, skiprows = 300001, nrows = 100000)\n",
        "pretrain_data = pd.concat([pretrain_data_0, pretrain_data_1, pretrain_data_2, pretrain_data_3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "6oPugpA6YRya",
        "outputId": "090a1646-63b5-41cf-b50c-97583ae6145c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(400000, 101)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-131fcd21-0748-4692-b475-d9d7dc899411\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>,</td>\n",
              "      <td>-0.013445</td>\n",
              "      <td>0.082912</td>\n",
              "      <td>0.095113</td>\n",
              "      <td>0.052493</td>\n",
              "      <td>0.069441</td>\n",
              "      <td>-0.010651</td>\n",
              "      <td>0.004321</td>\n",
              "      <td>-0.082824</td>\n",
              "      <td>0.051480</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099876</td>\n",
              "      <td>0.020649</td>\n",
              "      <td>-0.066902</td>\n",
              "      <td>0.077416</td>\n",
              "      <td>-0.147332</td>\n",
              "      <td>-0.021268</td>\n",
              "      <td>0.019100</td>\n",
              "      <td>-0.138095</td>\n",
              "      <td>0.077689</td>\n",
              "      <td>-0.210762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.</td>\n",
              "      <td>0.080173</td>\n",
              "      <td>0.048418</td>\n",
              "      <td>0.058027</td>\n",
              "      <td>0.055044</td>\n",
              "      <td>0.023451</td>\n",
              "      <td>-0.000025</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>-0.071703</td>\n",
              "      <td>0.054242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.183366</td>\n",
              "      <td>0.039830</td>\n",
              "      <td>-0.010186</td>\n",
              "      <td>0.075011</td>\n",
              "      <td>-0.128598</td>\n",
              "      <td>-0.020384</td>\n",
              "      <td>0.029758</td>\n",
              "      <td>-0.172362</td>\n",
              "      <td>0.126670</td>\n",
              "      <td>-0.188354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v√†</td>\n",
              "      <td>0.013720</td>\n",
              "      <td>0.058717</td>\n",
              "      <td>0.110645</td>\n",
              "      <td>0.066075</td>\n",
              "      <td>0.046535</td>\n",
              "      <td>-0.004956</td>\n",
              "      <td>-0.003579</td>\n",
              "      <td>-0.033581</td>\n",
              "      <td>0.043340</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.128276</td>\n",
              "      <td>-0.011903</td>\n",
              "      <td>-0.048510</td>\n",
              "      <td>0.085721</td>\n",
              "      <td>-0.133140</td>\n",
              "      <td>0.005551</td>\n",
              "      <td>0.043090</td>\n",
              "      <td>-0.154915</td>\n",
              "      <td>0.148186</td>\n",
              "      <td>-0.196749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c·ªßa</td>\n",
              "      <td>0.026101</td>\n",
              "      <td>0.033375</td>\n",
              "      <td>0.166609</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.017971</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.067402</td>\n",
              "      <td>0.002216</td>\n",
              "      <td>0.116908</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.137093</td>\n",
              "      <td>0.036225</td>\n",
              "      <td>-0.026152</td>\n",
              "      <td>0.148379</td>\n",
              "      <td>-0.151303</td>\n",
              "      <td>-0.039304</td>\n",
              "      <td>0.016051</td>\n",
              "      <td>-0.123603</td>\n",
              "      <td>0.107642</td>\n",
              "      <td>-0.222042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l√†</td>\n",
              "      <td>0.031769</td>\n",
              "      <td>0.048661</td>\n",
              "      <td>0.138932</td>\n",
              "      <td>-0.068711</td>\n",
              "      <td>0.049129</td>\n",
              "      <td>-0.014016</td>\n",
              "      <td>0.066129</td>\n",
              "      <td>0.013496</td>\n",
              "      <td>0.028830</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.124612</td>\n",
              "      <td>0.031029</td>\n",
              "      <td>-0.069093</td>\n",
              "      <td>0.085157</td>\n",
              "      <td>-0.106477</td>\n",
              "      <td>-0.006654</td>\n",
              "      <td>-0.006391</td>\n",
              "      <td>-0.161527</td>\n",
              "      <td>0.107603</td>\n",
              "      <td>-0.208509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-131fcd21-0748-4692-b475-d9d7dc899411')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-131fcd21-0748-4692-b475-d9d7dc899411 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-131fcd21-0748-4692-b475-d9d7dc899411');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   0         1         2         3         4         5         6         7    \\\n",
              "0    , -0.013445  0.082912  0.095113  0.052493  0.069441 -0.010651  0.004321   \n",
              "1    .  0.080173  0.048418  0.058027  0.055044  0.023451 -0.000025  0.000599   \n",
              "2   v√†  0.013720  0.058717  0.110645  0.066075  0.046535 -0.004956 -0.003579   \n",
              "3  c·ªßa  0.026101  0.033375  0.166609  0.013060  0.017971  0.006579  0.067402   \n",
              "4   l√†  0.031769  0.048661  0.138932 -0.068711  0.049129 -0.014016  0.066129   \n",
              "\n",
              "        8         9    ...       91        92        93        94        95   \\\n",
              "0 -0.082824  0.051480  ... -0.099876  0.020649 -0.066902  0.077416 -0.147332   \n",
              "1 -0.071703  0.054242  ... -0.183366  0.039830 -0.010186  0.075011 -0.128598   \n",
              "2 -0.033581  0.043340  ... -0.128276 -0.011903 -0.048510  0.085721 -0.133140   \n",
              "3  0.002216  0.116908  ... -0.137093  0.036225 -0.026152  0.148379 -0.151303   \n",
              "4  0.013496  0.028830  ... -0.124612  0.031029 -0.069093  0.085157 -0.106477   \n",
              "\n",
              "        96        97        98        99        100  \n",
              "0 -0.021268  0.019100 -0.138095  0.077689 -0.210762  \n",
              "1 -0.020384  0.029758 -0.172362  0.126670 -0.188354  \n",
              "2  0.005551  0.043090 -0.154915  0.148186 -0.196749  \n",
              "3 -0.039304  0.016051 -0.123603  0.107642 -0.222042  \n",
              "4 -0.006654 -0.006391 -0.161527  0.107603 -0.208509  \n",
              "\n",
              "[5 rows x 101 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(pretrain_data.shape)\n",
        "pretrain_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APQ4iL6QPCUy"
      },
      "outputs": [],
      "source": [
        "word_embedding_dict = {}\n",
        "border = np.sqrt(3/100)\n",
        "count = 0\n",
        "for word in list_of_words:\n",
        "  if pretrain_data.loc[pretrain_data[0] == word].shape[0] == 0:\n",
        "    word_embedding_dict[word] = np.random.uniform(-border,border, 100).tolist()\n",
        "  else:\n",
        "    temp = []\n",
        "    for x in range(1, 101):\n",
        "      _ = pretrain_data.loc[pretrain_data[0] == word, x].values[0]\n",
        "      temp.append(_)\n",
        "    word_embedding_dict[word] = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZEGxCuGTbhF",
        "outputId": "585c1c33-f826-4b8f-d466-8287f9798288"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7886"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word_embedding_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF_J5T1vBgE5"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LvVXYAGDpxu8",
        "outputId": "0a5d4c9d-b9a7-4950-dee3-5548885029b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"with open('saved_dictionary.pkl', 'rb') as f:\\n    loaded_dict = pickle.load(f)\""
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pickle\n",
        "with open('saved_dictionary.pkl', 'wb') as f:\n",
        "    pickle.dump(word_embedding_dict, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNUNpA8YBWG-"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsrxvVLNqgq5"
      },
      "outputs": [],
      "source": [
        "with open('saved_dictionary.pkl', 'rb') as f: #read from a pretrained word-embedding file\n",
        "    loaded_dict = pickle.load(f)\n",
        "\n",
        "border = np.sqrt(3/100)\n",
        "loaded_dict['UNK'] = np.random.uniform(-border,border, 100).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = pd.read_csv('train_word.csv')[['sent', 'anno']]\n",
        "print(f\"Dataset's shape: {trainset.shape}\")\n",
        "trainset.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "ZXj4qU6XvWC2",
        "outputId": "f4623790-e752-4a69-e614-c588b67c30d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset's shape: (5027, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                sent  \\\n",
              "0  ƒê·ªìng_th·ªùi , b·ªánh_vi·ªán ti·∫øp_t·ª•c th·ª±c_hi·ªán c√°c b...   \n",
              "1  \" S·ªë b·ªánh_vi·ªán c√≥_th·ªÉ ti·∫øp_nh·∫≠n b·ªánh_nh√¢n b·ªã s...   \n",
              "2  Ngo√†i_ra , nh·ªØng ng∆∞·ªùi ti·∫øp_x√∫c gi√°n_ti·∫øp ( ƒë√£...   \n",
              "\n",
              "                                                anno  \n",
              "0  O O O O O O O O O O O O O O O B-ORGANIZATION I...  \n",
              "1  O O O O O O O B-SYMPTOM_AND_DISEASE I-SYMPTOM_...  \n",
              "2  O O O O O O O O O O O O O O O O O O O O O O O ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbb571d3-a6dd-4aaa-be0f-889ad760e66c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>anno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ƒê·ªìng_th·ªùi , b·ªánh_vi·ªán ti·∫øp_t·ª•c th·ª±c_hi·ªán c√°c b...</td>\n",
              "      <td>O O O O O O O O O O O O O O O B-ORGANIZATION I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" S·ªë b·ªánh_vi·ªán c√≥_th·ªÉ ti·∫øp_nh·∫≠n b·ªánh_nh√¢n b·ªã s...</td>\n",
              "      <td>O O O O O O O B-SYMPTOM_AND_DISEASE I-SYMPTOM_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ngo√†i_ra , nh·ªØng ng∆∞·ªùi ti·∫øp_x√∫c gi√°n_ti·∫øp ( ƒë√£...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbb571d3-a6dd-4aaa-be0f-889ad760e66c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbb571d3-a6dd-4aaa-be0f-889ad760e66c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbb571d3-a6dd-4aaa-be0f-889ad760e66c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = pd.read_csv('test_word.csv')[['sent', 'anno']]\n",
        "print(f\"Dataset's shape: {testset.shape}\")\n",
        "testset.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "_GzVxbDvvhTP",
        "outputId": "c4a54df9-e30e-48fe-9564-d5d1fe382d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset's shape: (4000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                sent  \\\n",
              "0  T·ª´ 24 - 7 ƒë·∫øn 31 - 7 , b·ªánh_nh√¢n ƒë∆∞·ª£c m·∫π l√† b√†...   \n",
              "1  B√°c_sƒ© Tr·∫ßn_Thanh_Linh , t·ª´ B·ªánh_vi·ªán Ch·ª£_R·∫´y ...   \n",
              "2  Theo ƒë√≥ , S·ªü Y_t·∫ø B√¨nh_Thu·∫≠n cho bi·∫øt sau khi ...   \n",
              "\n",
              "                                                anno  \n",
              "0  O B-DATE I-DATE I-DATE O B-DATE I-DATE I-DATE ...  \n",
              "1  O O O O B-ORGANIZATION I-ORGANIZATION O O O O ...  \n",
              "2  O O O B-ORGANIZATION I-ORGANIZATION I-ORGANIZA...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88e90982-fa89-4d06-ae3c-1e3313f5d070\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>anno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T·ª´ 24 - 7 ƒë·∫øn 31 - 7 , b·ªánh_nh√¢n ƒë∆∞·ª£c m·∫π l√† b√†...</td>\n",
              "      <td>O B-DATE I-DATE I-DATE O B-DATE I-DATE I-DATE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B√°c_sƒ© Tr·∫ßn_Thanh_Linh , t·ª´ B·ªánh_vi·ªán Ch·ª£_R·∫´y ...</td>\n",
              "      <td>O O O O B-ORGANIZATION I-ORGANIZATION O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Theo ƒë√≥ , S·ªü Y_t·∫ø B√¨nh_Thu·∫≠n cho bi·∫øt sau khi ...</td>\n",
              "      <td>O O O B-ORGANIZATION I-ORGANIZATION I-ORGANIZA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e90982-fa89-4d06-ae3c-1e3313f5d070')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88e90982-fa89-4d06-ae3c-1e3313f5d070 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88e90982-fa89-4d06-ae3c-1e3313f5d070');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validset = pd.read_csv('val_word.csv')[['sent', 'anno']]\n",
        "print(f\"Dataset's shape: {validset.shape}\")\n",
        "validset.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "mp_s8OQYvnWy",
        "outputId": "79466be6-b812-4ecf-bf4b-31ea567d93c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset's shape: (1000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                sent  \\\n",
              "0  B√°c_sƒ© Nguy·ªÖn_Trung_Nguy√™n , Gi√°m_ƒë·ªëc Trung_t√¢...   \n",
              "1  \" B·ªánh_nh√¢n 812 \" , nam , 62 tu·ªïi , l√† nh√¢n_vi...   \n",
              "2  Trong s·ªë nh·ªØng ng∆∞·ªùi m√† c√¥ ·∫•y ƒë√£ ti·∫øp_x√∫c v·ªõi ...   \n",
              "\n",
              "                                                anno  \n",
              "0  O O O O B-ORGANIZATION I-ORGANIZATION I-ORGANI...  \n",
              "1  O O B-PATIENT_ID O O B-GENDER O B-AGE O O O B-...  \n",
              "2           O O O O O O O O O O O O B-ORGANIZATION O  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8887e04-12ab-45b2-9860-738654e0ce14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent</th>\n",
              "      <th>anno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B√°c_sƒ© Nguy·ªÖn_Trung_Nguy√™n , Gi√°m_ƒë·ªëc Trung_t√¢...</td>\n",
              "      <td>O O O O B-ORGANIZATION I-ORGANIZATION I-ORGANI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" B·ªánh_nh√¢n 812 \" , nam , 62 tu·ªïi , l√† nh√¢n_vi...</td>\n",
              "      <td>O O B-PATIENT_ID O O B-GENDER O B-AGE O O O B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trong s·ªë nh·ªØng ng∆∞·ªùi m√† c√¥ ·∫•y ƒë√£ ti·∫øp_x√∫c v·ªõi ...</td>\n",
              "      <td>O O O O O O O O O O O O B-ORGANIZATION O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8887e04-12ab-45b2-9860-738654e0ce14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8887e04-12ab-45b2-9860-738654e0ce14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8887e04-12ab-45b2-9860-738654e0ce14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GT52mOoCt9F"
      },
      "outputs": [],
      "source": [
        "word_to_ix = {}\n",
        "tag_to_ix = {}\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix[START_TAG] = 0\n",
        "tag_to_ix[STOP_TAG] = 1\n",
        "word_to_ix['UNK'] = 0\n",
        "\n",
        "for sentences, tags in zip(trainset['sent'].tolist(),trainset['anno'].tolist()):\n",
        "  for word in sentences.split():\n",
        "    if word not in word_to_ix.keys():\n",
        "      word_to_ix[word] = len(word_to_ix)\n",
        "  for tag in tags.split():\n",
        "    if tag not in tag_to_ix.keys():\n",
        "      tag_to_ix[tag] = len(tag_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clTGqy5VEWsc",
        "outputId": "89f2158c-5371-4caf-ef07-97cb116a890e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<START>': 0, '<STOP>': 1, 'O': 2, 'B-ORGANIZATION': 3, 'I-ORGANIZATION': 4, 'B-SYMPTOM_AND_DISEASE': 5, 'I-SYMPTOM_AND_DISEASE': 6, 'B-LOCATION': 7, 'B-DATE': 8, 'B-PATIENT_ID': 9, 'B-AGE': 10, 'B-NAME': 11, 'I-DATE': 12, 'B-JOB': 13, 'I-LOCATION': 14, 'B-TRANSPORTATION': 15, 'B-GENDER': 16, 'I-TRANSPORTATION': 17, 'I-JOB': 18, 'I-NAME': 19, 'I-AGE': 20, 'I-PATIENT_ID': 21}\n"
          ]
        }
      ],
      "source": [
        "print(tag_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of distinct words: {len(word_to_ix)-1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w8BUR230dub",
        "outputId": "a5774df0-2d11-42aa-d5f4-5d913ccdd189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of distinct words: 5167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2tag = dict()\n",
        "word2tag['word'] = list()\n",
        "word2tag['tag'] = list()\n",
        "\n",
        "for sentences, tags in zip(trainset['sent'].tolist(), trainset['anno'].tolist()):\n",
        "  for word, tag in zip (sentences.split(), tags.split()):\n",
        "    word2tag['word'].append(word)\n",
        "    word2tag['tag'].append(tag)\n",
        "dataset_df = pd.DataFrame(word2tag)"
      ],
      "metadata": {
        "id": "2GBJuI4n11ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mez8fjp22qqc",
        "outputId": "8baa35c1-825f-48c6-c89f-62a68fc3931e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        word tag\n",
              "0  ƒê·ªìng_th·ªùi   O\n",
              "1          ,   O\n",
              "2  b·ªánh_vi·ªán   O\n",
              "3   ti·∫øp_t·ª•c   O\n",
              "4  th·ª±c_hi·ªán   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d926f257-146e-483b-9a16-78bdd99ce33d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ƒê·ªìng_th·ªùi</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b·ªánh_vi·ªán</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ti·∫øp_t·ª•c</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>th·ª±c_hi·ªán</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d926f257-146e-483b-9a16-78bdd99ce33d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d926f257-146e-483b-9a16-78bdd99ce33d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d926f257-146e-483b-9a16-78bdd99ce33d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "09CasBwrBhF8",
        "outputId": "d0a200b8-1243-4771-d3b9-3178229e58f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6c7e3453d0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "dataset_df[dataset_df[\"tag\"]!=\"O\"][\"tag\"].value_counts().plot(kind=\"bar\", figsize=(10,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0clrIuUr3eW",
        "outputId": "7a31ae7d-c4a1-4d98-c9f3-9ed35078184c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique tag is 20\n",
            "Number of unique word is 5168\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of unique tag is {len(tag_to_ix)-2}\")\n",
        "print(f\"Number of unique word is {len(word_to_ix)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsSweX5Gr5D5"
      },
      "outputs": [],
      "source": [
        "full_text = \"\"\n",
        "\n",
        "for word in word_to_ix.keys():\n",
        "  full_text += word\n",
        "  full_text += \" \"\n",
        "\n",
        "int2char = dict(enumerate(set(full_text)))\n",
        "char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "int2char[len(char2int)] = 'UNK'\n",
        "char2int['UNK'] = len(char2int)\n",
        "\n",
        "list_of_pos = {\n",
        "    'X': 0,  #<Unk>\n",
        "    'A': 1,\n",
        "    'C': 2,\n",
        "    'E': 3,\n",
        "    'I': 4,\n",
        "    'L': 5,\n",
        "    'M': 6,\n",
        "    'N': 7,\n",
        "    'Nc': 8,\n",
        "    'Ny': 9,\n",
        "    'Np': 10,\n",
        "    'Nu': 11,\n",
        "    'P': 12,\n",
        "    'R': 13,\n",
        "    'S': 14,\n",
        "    'T': 15,\n",
        "    'V': 16,\n",
        "    'F': 17\n",
        "}\n",
        "\n",
        "def one_hot_encode(index, n_labels):\n",
        "    one_hot = [0] * n_labels\n",
        "    one_hot[index] = 1\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(char2int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTyjl-qasdz8",
        "outputId": "64a73d3a-9651-42fc-faf9-09b2559cd633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I': 0, '√©': 1, '·ª°': 2, '·ªë': 3, 'ƒÇ': 4, '·∫±': 5, '·ªÅ': 6, 'Ôøº': 7, 'G': 8, '·∫¢': 9, '·∫≠': 10, '·ªµ': 11, 'E': 12, 'z': 13, 'r': 14, 'h': 15, '·ªî': 16, '√≠': 17, '&': 18, 'N': 19, '·ª•': 20, 'X': 21, '·ª£': 22, '_': 23, '·ªÑ': 24, 'g': 25, ':': 26, 'H': 27, '√î': 28, 'S': 29, '/': 30, '·∫£': 31, '·∫°': 32, '·∫ª': 33, 'o': 34, '5': 35, '·∫Ø': 36, 'u': 37, '√ö': 38, 'Q': 39, '·ªπ': 40, '∆Ø': 41, 's': 42, '√™': 43, '2': 44, '√†': 45, '√Å': 46, 'C': 47, 'k': 48, '·ªØ': 49, '·ªó': 50, '.': 51, '‚Ä¶': 52, '·ªç': 53, '·∫≥': 54, 'n': 55, 'l': 56, '1': 57, 'L': 58, '4': 59, 'V': 60, '√®': 61, 'Y': 62, '·ªï': 63, ' ': 64, 'ƒë': 65, ';': 66, '?': 67, 'ƒÉ': 68, 'W': 69, '·∫©': 70, ')': 71, '·ª´': 72, 'w': 73, '√Ç': 74, '8': 75, 'ƒ®': 76, '·ª≥': 77, '·∫µ': 78, '7': 79, '√≥': 80, '·∫∑': 81, '·ª∑': 82, '√°': 83, 'B': 84, '·ªü': 85, '·ªâ': 86, '·∫ß': 87, '√£': 88, '√ç': 89, 'x': 90, '·ªû': 91, '9': 92, 'D': 93, 'e': 94, '3': 95, '·ªÖ': 96, '\"': 97, '·ªô': 98, '·ª±': 99, 'J': 100, '√µ': 101, '·∫§': 102, 'p': 103, '\\u200b': 104, '·∫π': 105, '·ªß': 106, '*': 107, '√¥': 108, '+': 109, '√ù': 110, '∆°': 111, '-': 112, '·ª©': 113, 'ƒ©': 114, '%': 115, 'ƒê': 116, 'T': 117, '√Ä': 118, '·ªá': 119, '6': 120, '‚Äú': 121, 'F': 122, '√¢': 123, '0': 124, '·ªã': 125, 'P': 126, '·ªÜ': 127, '·∫´': 128, '‚Äù': 129, '∆∞': 130, '≈©': 131, 'v': 132, '‚Äì': 133, \"'\": 134, '·∫Ω': 135, 'K': 136, '√¨': 137, 'y': 138, 't': 139, 'i': 140, 'Z': 141, ',': 142, '√∫': 143, '·ªù': 144, '√≤': 145, '·ªì': 146, '√Ω': 147, 'O': 148, '·∫ø': 149, 'q': 150, 'U': 151, '·∫•': 152, 'R': 153, '·ª≠': 154, 'b': 155, '·ªõ': 156, '√π': 157, '·ªè': 158, 'a': 159, 'm': 160, '¬∞': 161, 'd': 162, '(': 163, 'c': 164, '·ªÉ': 165, 'M': 166, 'f': 167, 'A': 168, 'UNK': 169}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5kiC7W_ajY5"
      },
      "outputs": [],
      "source": [
        "training_data = []\n",
        "for sent, tag in zip(trainset['sent'].tolist(), trainset['anno'].tolist()):\n",
        "  list_word = sent.split()\n",
        "  embed = []\n",
        "  sequence_pos = []\n",
        "  list_tag = [tag_to_ix[t] for t in tag.split()]\n",
        "  sequence_char = []\n",
        "  for word in list_word:\n",
        "    embed.append(loaded_dict[word])\n",
        "    temp = []\n",
        "    for ch in list(word):\n",
        "      temp.append(char2int[ch])\n",
        "    sequence_char.append(temp)\n",
        "  for pos in ViPosTagger.postagging(sent)[1]:\n",
        "    sequence_pos.append(one_hot_encode(list_of_pos[pos], len(list_of_pos)))\n",
        "\n",
        "  training_data.append((list_word, embed, list_tag, sequence_pos, sequence_char))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validating_data = []\n",
        "for sent, tag in zip(validset['sent'].tolist(), validset['anno'].tolist()):\n",
        "  list_word = sent.split()\n",
        "  embed = []\n",
        "  sequence_pos = []\n",
        "  list_tag = [tag_to_ix[t] for t in tag.split()]\n",
        "  sequence_char = []\n",
        "  for word in list_word:\n",
        "    if word not in loaded_dict:\n",
        "      embed.append(loaded_dict['UNK'])\n",
        "    else:\n",
        "      embed.append(loaded_dict[word])\n",
        "    temp = []\n",
        "    for ch in list(word):\n",
        "      if ch not in char2int:\n",
        "        temp.append(char2int['UNK'])\n",
        "      else:\n",
        "        temp.append(char2int[ch])\n",
        "    sequence_char.append(temp)\n",
        "  for pos in ViPosTagger.postagging(sent)[1]:\n",
        "    sequence_pos.append(one_hot_encode(list_of_pos[pos], len(list_of_pos)))\n",
        "\n",
        "  validating_data.append((list_word, embed, list_tag, sequence_pos, sequence_char))"
      ],
      "metadata": {
        "id": "bKNE205GzJZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data = []\n",
        "for sent, tag in zip(testset['sent'].tolist(), testset['anno'].tolist()):\n",
        "  list_word = sent.split()\n",
        "  embed = []\n",
        "  sequence_pos = []\n",
        "  list_tag = [tag_to_ix[t] for t in tag.split()]\n",
        "  sequence_char = []\n",
        "  for word in list_word:\n",
        "    if word not in loaded_dict:\n",
        "      embed.append(loaded_dict['UNK'])\n",
        "    else:\n",
        "      embed.append(loaded_dict[word])\n",
        "    temp = []\n",
        "    for ch in list(word):\n",
        "      if ch not in char2int:\n",
        "        temp.append(char2int['UNK'])\n",
        "      else:\n",
        "        temp.append(char2int[ch])\n",
        "    sequence_char.append(temp)\n",
        "  for pos in ViPosTagger.postagging(sent)[1]:\n",
        "    sequence_pos.append(one_hot_encode(list_of_pos[pos], len(list_of_pos)))\n",
        "  testing_data.append((list_word, embed, list_tag, sequence_pos, sequence_char))"
      ],
      "metadata": {
        "id": "LmURFw1hvEYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yaXyYIFdwhb",
        "outputId": "f615b163-e3d9-4575-8f02-118aa7e70f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H√¥m_qua', ',', 'hai', 'b·ªánh_nh√¢n', 'Covid', '-', '19', 'c≈©ng', 't·ª≠_vong', ',', 'c√≥', 'b·ªánh', 'n·ªÅn', 'suy', 'th·∫≠n', 'm·∫°n', '.']\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 6, 6, 2]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
            "[[27, 108, 160, 23, 150, 37, 159], [142], [15, 159, 140], [155, 119, 55, 15, 23, 55, 15, 123, 55], [47, 34, 132, 140, 162], [112], [57, 92], [164, 131, 55, 25], [139, 154, 23, 132, 34, 55, 25], [142], [164, 80], [155, 119, 55, 15], [55, 6, 55], [42, 37, 138], [139, 15, 10, 55], [160, 32, 55], [51]]\n"
          ]
        }
      ],
      "source": [
        "print(training_data[10][0])\n",
        "print(training_data[10][2])\n",
        "print(training_data[10][3])\n",
        "print(training_data[10][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85a6WjochJJD",
        "outputId": "74d962c6-d5d1-4da2-cce6-b3d8be846dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5027\n",
            "1000\n",
            "4000\n"
          ]
        }
      ],
      "source": [
        "print(len(training_data))\n",
        "print(len(validating_data))\n",
        "print(len(testing_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q9B5DO2B7no"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG5iXG8V7vhc"
      },
      "outputs": [],
      "source": [
        "def argmax(vec):\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "def generate_batch(df, size):\n",
        "    sent_list = []\n",
        "    embeds_list = []\n",
        "    tags_list = []\n",
        "    pos_list = []\n",
        "    char_list = []\n",
        "    for item in df:\n",
        "        sent_list.append(item[0])\n",
        "        embeds_list += item[1]\n",
        "        tags_list += item[2]\n",
        "        pos_list += item[3]\n",
        "        char_list += item[4]\n",
        "        if len(sent_list) == size:\n",
        "            yield sent_list, embeds_list, tags_list, pos_list, char_list\n",
        "            sent_list = []\n",
        "            embeds_list = []\n",
        "            tags_list = []\n",
        "            pos_list = []\n",
        "            char_list = []\n",
        "            \n",
        "class CharEmbedding(nn.Module):\n",
        "  def __init__(self, embeddingSize ,hiddenSize, charSize):\n",
        "    super(CharEmbedding, self).__init__()\n",
        "    self.embeddingSize = embeddingSize\n",
        "    self.hiddenSize = hiddenSize\n",
        "    self.embed = nn.Embedding(charSize, embeddingSize)\n",
        "    self.BiLSTM = nn.LSTM(embeddingSize, hiddenSize, batch_first = True, bidirectional=True)\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    embeddingMatrix = torch.empty(size = (len(sentence), self.hiddenSize*2))\n",
        "    hidden, cell = (torch.randn(2, 1, self.hiddenSize),\n",
        "                    torch.randn(2, 1, self.hiddenSize))\n",
        "    for i, word in enumerate(sentence):\n",
        "      for char in word:\n",
        "        embeds = self.embed(torch.tensor(char))\n",
        "        out, (hidden, cell) = self.BiLSTM(embeds.view(1, 1, -1), (hidden, cell))\n",
        "      embeddingMatrix[i] = out\n",
        "    return embeddingMatrix\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = (torch.randn(2, 1, self.hidden_dim // 2),torch.randn(2, 1, self.hidden_dim // 2))\n",
        "        return hidden\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "        forward_var = forward_var\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = sentence.view(len(sentence), 1, -1)     #self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        forward_var = forward_var\n",
        "        \n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                \n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WordEmbedding"
      ],
      "metadata": {
        "id": "kv692Uun9Zm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "#char\n",
        "embeddingSize = 10\n",
        "hiddenSize = 25\n",
        "charSize = len(char2int)\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3"
      ],
      "metadata": {
        "id": "RCxqUu0I9ijk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "metadata": {
        "id": "H9SqNATX-tVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "patience = 2\n",
        "trigger = 0\n",
        "\n",
        "list_word = []\n",
        "list_tag = []\n",
        "\n",
        "for i in range(len(validating_data)):\n",
        "    list_word.extend(validating_data[i][1])\n",
        "    list_tag.extend(validating_data[i][2])\n",
        "\n",
        "with torch.no_grad():\n",
        "  test = torch.tensor(list_word, dtype = torch.float32)\n",
        "  last_loss = model.neg_log_likelihood(test, torch.tensor(list_tag)).item()\n",
        "  print(f\"Validation Loss before training: {last_loss}\")\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch: {epoch+1}/{EPOCHS}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for index, (sent, embeds, tags, pos, char) in enumerate(generate_batch(training_data, BATCH_SIZE)):\n",
        "        model.zero_grad()\n",
        "\n",
        "        inputs = torch.tensor(embeds, dtype = torch.float32)\n",
        "        targets = torch.tensor(tags)\n",
        "        \n",
        "        train_loss = model.neg_log_likelihood(inputs, targets)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "        print(index, end = \" \")\n",
        "        if index % 5 == 0:\n",
        "          torch.save(model.state_dict(), '/content/drive/MyDrive/AI/WordEmbed.pt')     \n",
        "    with torch.no_grad():\n",
        "      test = torch.tensor(list_word, dtype = torch.float32)\n",
        "      current_loss = model.neg_log_likelihood(test, torch.tensor(list_tag)).item()\n",
        "    if current_loss > last_loss:\n",
        "      trigger += 1\n",
        "    else:\n",
        "      last_loss = current_loss\n",
        "    if trigger == patience:\n",
        "      break\n",
        "    print(f\"epoch {epoch+1}/{EPOCHS} with time: {time.time() - start_time} - validloss: {current_loss}\") \n",
        "    start_time = time.time()"
      ],
      "metadata": {
        "id": "IWE1NvBo_Ud3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aafd349a-3d4f-48f9-cdaf-bf5e3dc0ac8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss before training: 91002.3203125\n",
            "Epoch: 1/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 1/10 with time: 1006.3140444755554 - validloss: 34643.6796875\n",
            "Epoch: 2/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 2/10 with time: 1008.781685590744 - validloss: 23910.828125\n",
            "Epoch: 3/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 3/10 with time: 1008.945996761322 - validloss: 18385.6484375\n",
            "Epoch: 4/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 4/10 with time: 1008.101212978363 - validloss: 14988.171875\n",
            "Epoch: 5/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 5/10 with time: 1014.5274240970612 - validloss: 13354.484375\n",
            "Epoch: 6/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 6/10 with time: 1030.9164054393768 - validloss: 12188.765625\n",
            "Epoch: 7/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 7/10 with time: 1008.1651694774628 - validloss: 11335.421875\n",
            "Epoch: 8/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 8/10 with time: 1018.3073978424072 - validloss: 10707.71875\n",
            "Epoch: 9/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 9/10 with time: 1021.5004639625549 - validloss: 10303.546875\n",
            "Epoch: 10/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 10/10 with time: 1007.833181142807 - validloss: 9944.265625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/AI/WordEmbed.pt')"
      ],
      "metadata": {
        "id": "ltl1DEvqVZjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREDICT**"
      ],
      "metadata": {
        "id": "ij9vTLqrv0_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "#char\n",
        "embeddingSize = 10\n",
        "hiddenSize = 25\n",
        "charSize = len(char2int)\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "model.load_state_dict(torch.load('WordEmbed.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuBtYnmzvzf8",
        "outputId": "4d3d2c5c-0145-41f4-bcc4-bacef4b62d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"predict1.txt\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "for index, (sent, embeds, tags, pos, char) in enumerate(testing_data):\n",
        "  inputs = torch.tensor(embeds, dtype=torch.float32)\n",
        "  targets = torch.tensor(tags)\n",
        "  _, pred_targets = model(inputs)\n",
        "  pred_tag = [list(tag_to_ix.keys())[list(tag_to_ix.values()).index(tag)] for tag in pred_targets]\n",
        "  true_tag = [list(tag_to_ix.keys())[list(tag_to_ix.values()).index(tag)] for tag in targets]\n",
        "  for word, tags, pred in zip(testing_data[index][0], true_tag, pred_tag):\n",
        "    f.write(\"{} a {} {}\\n\".format(word, tags, pred))"
      ],
      "metadata": {
        "id": "RQkObZ45uhAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python conlleval.py < predict1.txt > result1.txt"
      ],
      "metadata": {
        "id": "ke06uI7JxpmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/AI/result1.txt'\n",
        "with open(path, 'r') as result:\n",
        "  print(result.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1TOCDNEyKEr",
        "outputId": "996fea48-d00b-49cc-c118-9ab4e1ce9e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed 108242 tokens with 14482 phrases; found: 11756 phrases; correct: 10127.\n",
            "accuracy:  70.48%; (non-O)\n",
            "accuracy:  91.63%; precision:  86.14%; recall:  69.93%; FB1:  77.19\n",
            "              AGE: precision:  91.26%; recall:  90.88%; FB1:  91.07  721\n",
            "             DATE: precision:  88.06%; recall:  79.04%; FB1:  83.30  1884\n",
            "           GENDER: precision:  93.97%; recall:  89.24%; FB1:  91.54  547\n",
            "              JOB: precision:  53.06%; recall:  11.93%; FB1:  19.48  49\n",
            "         LOCATION: precision:  86.52%; recall:  67.72%; FB1:  75.97  4183\n",
            "             NAME: precision:  86.67%; recall:  20.86%; FB1:  33.62  90\n",
            "     ORGANIZATION: precision:  66.40%; recall:  58.29%; FB1:  62.08  863\n",
            "       PATIENT_ID: precision:  90.50%; recall:  83.00%; FB1:  86.59  2326\n",
            "SYMPTOM_AND_DISEASE: precision:  80.81%; recall:  53.51%; FB1:  64.39  933\n",
            "   TRANSPORTATION: precision:  88.12%; recall:  64.38%; FB1:  74.41  160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WordEmbedding + Char"
      ],
      "metadata": {
        "id": "gfjTHSWYWSP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 150\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "#char\n",
        "embeddingSize = 10\n",
        "hiddenSize = 25\n",
        "charSize = len(char2int)\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3"
      ],
      "metadata": {
        "id": "HclQQrv0WVE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "charModel = CharEmbedding(embeddingSize, hiddenSize, charSize)\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                {'params': model.parameters()},\n",
        "                {'params': charModel.parameters(), 'lr': 1e-3}\n",
        "            ], lr=1e-3)"
      ],
      "metadata": {
        "id": "pljNpgnxWxJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "patience = 2\n",
        "trigger = 0\n",
        "\n",
        "list_word = []\n",
        "list_tag = []\n",
        "list_char = []\n",
        "for i in range(len(validating_data)):\n",
        "    list_char.extend(validating_data[i][-1])\n",
        "    list_word.extend(validating_data[i][1])\n",
        "    list_tag.extend(validating_data[i][2])\n",
        "\n",
        "with torch.no_grad():\n",
        "  out = charModel(list_char)\n",
        "  test = torch.cat((torch.tensor(list_word, dtype = torch.float32), out), dim = 1)\n",
        "  last_loss = model.neg_log_likelihood(test, torch.tensor(list_tag)).item()\n",
        "  print(f\"Validation Loss before training: {last_loss}\")\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch: {epoch+1}/{EPOCHS}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for index, (sent, embeds, tags, pos, char) in enumerate(generate_batch(training_data, BATCH_SIZE)):\n",
        "        model.zero_grad()\n",
        "        charModel.zero_grad()\n",
        "\n",
        "        embeds = torch.tensor(embeds, dtype = torch.float32)\n",
        "        char = charModel(char)\n",
        "        inputs = torch.cat((embeds, char), dim=1)\n",
        "\n",
        "        targets = torch.tensor(tags)\n",
        "\n",
        "        train_loss = model.neg_log_likelihood(inputs, targets)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "        print(index, end = \" \")\n",
        "        if index % 5 == 0:\n",
        "          torch.save(model.state_dict(), '/content/drive/MyDrive/AI/WordEmbedChar.pt')\n",
        "          torch.save(charModel.state_dict(), '/content/drive/MyDrive/AI/WordEmbedChar1.pt')\n",
        "    with torch.no_grad():\n",
        "      out = charModel(list_char)\n",
        "      test = torch.cat((torch.tensor(list_word, dtype = torch.float32), out), dim = 1)\n",
        "      current_loss = model.neg_log_likelihood(test, torch.tensor(list_tag)).item()\n",
        "    print(f\"epoch {epoch+1}/{EPOCHS} with time: {time.time() - start_time} - validloss: {current_loss}\") \n",
        "    start_time = time.time()\n",
        "    if current_loss > last_loss:\n",
        "      trigger += 1\n",
        "    else:\n",
        "      last_loss = current_loss\n",
        "    if trigger == patience:\n",
        "      break"
      ],
      "metadata": {
        "id": "_kXzMgpnW0kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d44d01c-6473-493d-f2c0-2efda86b562e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss before training: 134733.265625\n",
            "Epoch: 1/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 1/10 with time: 1350.9037110805511 - validloss: 32853.28125\n",
            "Epoch: 2/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 2/10 with time: 1359.6248598098755 - validloss: 20381.34375\n",
            "Epoch: 3/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 3/10 with time: 1358.564025402069 - validloss: 14993.625\n",
            "Epoch: 4/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 4/10 with time: 1362.2385606765747 - validloss: 11302.875\n",
            "Epoch: 5/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 5/10 with time: 1354.635594367981 - validloss: 9455.71875\n",
            "Epoch: 6/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 6/10 with time: 1360.088918209076 - validloss: 8424.46875\n",
            "Epoch: 7/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 7/10 with time: 1356.7415843009949 - validloss: 8045.125\n",
            "Epoch: 8/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 8/10 with time: 1359.0755801200867 - validloss: 7614.9375\n",
            "Epoch: 9/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 9/10 with time: 1355.308685541153 - validloss: 7292.875\n",
            "Epoch: 10/10\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 10/10 with time: 1362.4697442054749 - validloss: 7018.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/AI/WordEmbedChar.pt')\n",
        "torch.save(charModel.state_dict(), '/content/drive/MyDrive/AI/WordEmbedChar1.pt')"
      ],
      "metadata": {
        "id": "tS85BMJRKquX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 150\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "#char\n",
        "embeddingSize = 10\n",
        "hiddenSize = 25\n",
        "charSize = len(char2int)\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "charModel = CharEmbedding(embeddingSize, hiddenSize, charSize)\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                {'params': model.parameters()},\n",
        "                {'params': charModel.parameters(), 'lr': 1e-3}\n",
        "            ], lr=1e-3)\n",
        "\n",
        "model.load_state_dict(torch.load('WordEmbedChar.pt'))\n",
        "print(model.eval())\n",
        "charModel.load_state_dict(torch.load('WordEmbedChar1.pt'))\n",
        "print(charModel.eval())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OdiQqK-4J3I",
        "outputId": "6c0f4976-7acc-4dfe-dd47-8d05b3de0715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiLSTM_CRF(\n",
            "  (lstm): LSTM(150, 100, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=200, out_features=22, bias=True)\n",
            ")\n",
            "CharEmbedding(\n",
            "  (embed): Embedding(170, 10)\n",
            "  (BiLSTM): LSTM(10, 25, batch_first=True, bidirectional=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"predict2_temp.txt\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "for index, (sent, embeds, tags, pos, char) in enumerate(testing_data):\n",
        "  embeds = torch.tensor(embeds, dtype=torch.float32)\n",
        "  char_embed = charModel(char)\n",
        "\n",
        "  inputs = torch.cat((embeds,char_embed), 1)\n",
        "  targets = torch.tensor(tags)\n",
        "\n",
        "  _, pred_targets = model(inputs)\n",
        "  pred_tag = [list(tag_to_ix.keys())[list(tag_to_ix.values()).index(tag)] for tag in pred_targets]\n",
        "  true_tag = [list(tag_to_ix.keys())[list(tag_to_ix.values()).index(tag)] for tag in targets]\n",
        "  for word, tags, pred in zip(testing_data[index][0], true_tag, pred_tag):\n",
        "      f.write(\"{} a {} {}\\n\".format(word, tags, pred))"
      ],
      "metadata": {
        "id": "wrNcjxND4f7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python conlleval.py < predict2.txt > result2.txt\n",
        "path = '/content/drive/MyDrive/AI/result2.txt'\n",
        "with open(path, 'r') as result:\n",
        "  print(result.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl65oL187D19",
        "outputId": "7d79b689-adf5-4782-c3da-2d82a431ed40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed 110431 tokens with 14723 phrases; found: 13964 phrases; correct: 11825.\n",
            "accuracy:  78.16%; (non-O)\n",
            "accuracy:  93.66%; precision:  84.68%; recall:  80.32%; FB1:  82.44\n",
            "              AGE: precision:  91.53%; recall:  91.66%; FB1:  91.59  732\n",
            "             DATE: precision:  88.43%; recall:  95.42%; FB1:  91.79  2307\n",
            "           GENDER: precision:  92.13%; recall:  89.10%; FB1:  90.59  559\n",
            "              JOB: precision: 100.00%; recall:   6.31%; FB1:  11.86  14\n",
            "         LOCATION: precision:  83.25%; recall:  78.91%; FB1:  81.02  5145\n",
            "             NAME: precision:  85.82%; recall:  60.85%; FB1:  71.21  268\n",
            "     ORGANIZATION: precision:  66.27%; recall:  61.48%; FB1:  63.79  925\n",
            "       PATIENT_ID: precision:  92.93%; recall:  97.58%; FB1:  95.20  2731\n",
            "SYMPTOM_AND_DISEASE: precision:  69.52%; recall:  54.03%; FB1:  60.80  1109\n",
            "   TRANSPORTATION: precision:  86.78%; recall:  67.71%; FB1:  76.07  174\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WordEmbedding + Char + POS"
      ],
      "metadata": {
        "id": "ZWJyiZdrWa9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 168\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "#char\n",
        "embeddingSize = 10\n",
        "hiddenSize = 25\n",
        "charSize = len(char2int)\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3"
      ],
      "metadata": {
        "id": "AIdCBQLWWgIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "charModel = CharEmbedding(embeddingSize, hiddenSize, charSize)\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                {'params': model.parameters()},\n",
        "                {'params': charModel.parameters(), 'lr': 1e-3}\n",
        "            ], lr=1e-3)"
      ],
      "metadata": {
        "id": "efdvjXlH2n0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "patience = 2\n",
        "trigger = 0\n",
        "\n",
        "list_word = []\n",
        "list_tag = []\n",
        "list_char = []\n",
        "list_pos = []\n",
        "for i in range(len(validating_data)):\n",
        "    list_char.extend(validating_data[i][-1])\n",
        "    list_word.extend(validating_data[i][1])\n",
        "    list_tag.extend(validating_data[i][2])\n",
        "    list_pos.extend(validating_data[i][3])\n",
        "\n",
        "with torch.no_grad():\n",
        "  out = charModel(list_char)\n",
        "  test = torch.cat((torch.tensor(list_word, dtype = torch.float32), out, torch.tensor(list_pos, dtype = torch.float32)), dim = 1)\n",
        "  last_loss = model.neg_log_likelihood(test, torch.tensor(list_tag)).item()\n",
        "  print(f\"Validation Loss before training: {last_loss}\")\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch: {epoch+1}/{EPOCHS}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for index, (sent, embeds, tags, pos, char) in enumerate(generate_batch(training_data, BATCH_SIZE)):\n",
        "        model.zero_grad()\n",
        "        charModel.zero_grad()\n",
        "\n",
        "        embeds = torch.tensor(embeds, dtype = torch.float32)\n",
        "        pos = torch.tensor(pos, dtype = torch.float32)\n",
        "        char = charModel(char)\n",
        "        inputs = torch.cat((embeds, char, pos), dim=1)\n",
        "\n",
        "        targets = torch.tensor(tags)\n",
        "\n",
        "        train_loss = model.neg_log_likelihood(inputs, targets)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "        print(index, end = \" \")  \n",
        "        if index % 10 == 0:\n",
        "          torch.save(model.state_dict(), '/content/drive/MyDrive/AI/WordEmbedCharPOS.pt')\n",
        "          torch.save(charModel.state_dict(), '/content/drive/MyDrive/AI/WordEmbedCharPOS1.pt')\n",
        "          \n",
        "    with torch.no_grad():\n",
        "      out = charModel(list_char)\n",
        "      test = torch.cat((torch.tensor(list_word, dtype = torch.float32), out, torch.tensor(list_pos, dtype = torch.float32)), dim = 1)\n",
        "      current_loss = model.neg_log_likelihood(test, torch.tensor(list_tag)).item()\n",
        "    print(f\"epoch {epoch+1}/{EPOCHS} with time: {time.time() - start_time} - validloss: {current_loss}\") \n",
        "    start_time = time.time()\n",
        "    if current_loss > last_loss:\n",
        "      trigger += 1\n",
        "    else:\n",
        "      last_loss = current_loss\n",
        "      name = '/content/drive/MyDrive/AI/model/WordEmbedCharPOS_epoch'+str(epoch+1)+'.pt'\n",
        "      nameChar = '/content/drive/MyDrive/AI/model/WordEmbedCharPOS1_epoch'+str(epoch+1)+'.pt'\n",
        "      torch.save(model.state_dict(), name)\n",
        "      torch.save(charModel.state_dict(), nameChar)\n",
        "    if trigger == patience:\n",
        "      break"
      ],
      "metadata": {
        "id": "KXWAfUz12ycV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "12ef7007-9356-475f-d74c-5b7a73310083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss before training: 93794.90625\n",
            "Epoch: 1/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 1/30 with time: 1352.900033712387 - validloss: 25009.0390625\n",
            "Epoch: 2/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 2/30 with time: 1350.6949243545532 - validloss: 12633.375\n",
            "Epoch: 3/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 3/30 with time: 1348.466332435608 - validloss: 8890.921875\n",
            "Epoch: 4/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 4/30 with time: 1362.2760846614838 - validloss: 7680.78125\n",
            "Epoch: 5/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-71d54d37e9c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcharModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-e14a0d453226>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBiLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m       \u001b[0membeddingMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membeddingMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 770\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 168\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "#char\n",
        "embeddingSize = 10\n",
        "hiddenSize = 25\n",
        "charSize = len(char2int)\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "charModel = CharEmbedding(embeddingSize, hiddenSize, charSize)\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                {'params': model.parameters()},\n",
        "                {'params': charModel.parameters(), 'lr': 1e-3}\n",
        "            ], lr=1e-3)\n",
        "\n",
        "model.load_state_dict(torch.load('Copy of WordEmbedCharPOS_epoch4.pt'))\n",
        "print(model.eval())\n",
        "charModel.load_state_dict(torch.load('Copy of WordEmbedCharPOS1_epoch4.pt'))\n",
        "print(charModel.eval())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WXF36X65XVd",
        "outputId": "5024fea3-e511-43e2-d7ab-461edef5231d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiLSTM_CRF(\n",
            "  (lstm): LSTM(168, 100, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=200, out_features=22, bias=True)\n",
            ")\n",
            "CharEmbedding(\n",
            "  (embed): Embedding(170, 10)\n",
            "  (BiLSTM): LSTM(10, 25, batch_first=True, bidirectional=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 2\n",
        "trigger = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  out = charModel(list_char)\n",
        "  test = torch.cat((torch.tensor(list_word, dtype = torch.float32), out, torch.tensor(list_pos, dtype = torch.float32)), dim = 1)\n",
        "  last_loss = model.neg_log_likelihood(test, torch.tensor(list_tag)).item()\n",
        "  print(f\"Validation Loss before training: {last_loss}\")\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch: {epoch+5}/{EPOCHS}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for index, (sent, embeds, tags, pos, char) in enumerate(generate_batch(training_data, BATCH_SIZE)):\n",
        "        model.zero_grad()\n",
        "        charModel.zero_grad()\n",
        "\n",
        "        embeds = torch.tensor(embeds, dtype = torch.float32)\n",
        "        pos = torch.tensor(pos, dtype = torch.float32)\n",
        "        char = charModel(char)\n",
        "        inputs = torch.cat((embeds, char, pos), dim=1)\n",
        "\n",
        "        targets = torch.tensor(tags)\n",
        "\n",
        "        train_loss = model.neg_log_likelihood(inputs, targets)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "        print(index, end = \" \")  \n",
        "        if index % 10 == 0:\n",
        "          torch.save(model.state_dict(), '/content/drive/MyDrive/AI/WordEmbedCharPOS.pt')\n",
        "          torch.save(charModel.state_dict(), '/content/drive/MyDrive/AI/WordEmbedCharPOS1.pt')\n",
        "          \n",
        "    with torch.no_grad():\n",
        "      out = charModel(list_char)\n",
        "      test = torch.cat((torch.tensor(list_word, dtype = torch.float32), out, torch.tensor(list_pos, dtype = torch.float32)), dim = 1)\n",
        "      current_loss = model.neg_log_likelihood(test, torch.tensor(list_tag)).item()\n",
        "    print(f\"epoch {epoch+5}/{EPOCHS} with time: {time.time() - start_time} - validloss: {current_loss}\") \n",
        "    start_time = time.time()\n",
        "    if current_loss > last_loss:\n",
        "      trigger += 1\n",
        "    else:\n",
        "      last_loss = current_loss\n",
        "      name = '/content/drive/MyDrive/AI/model/WordEmbedCharPOS_epoch'+str(epoch+5)+'.pt'\n",
        "      nameChar = '/content/drive/MyDrive/AI/model/WordEmbedCharPOS1_epoch'+str(epoch+5)+'.pt'\n",
        "      torch.save(model.state_dict(), name)\n",
        "      torch.save(charModel.state_dict(), nameChar)\n",
        "    if trigger == patience:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUbvIeFA6ah9",
        "outputId": "bfd3d091-f744-47e1-a549-19ba69d77a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss before training: 7680.359375\n",
            "Epoch: 5/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 5/30 with time: 1383.5425879955292 - validloss: 6935.375\n",
            "Epoch: 6/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 6/30 with time: 1393.4116961956024 - validloss: 6506.671875\n",
            "Epoch: 7/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 7/30 with time: 1387.0458419322968 - validloss: 6328.6875\n",
            "Epoch: 8/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 8/30 with time: 1396.1584572792053 - validloss: 6141.984375\n",
            "Epoch: 9/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 9/30 with time: 1383.1108028888702 - validloss: 5981.921875\n",
            "Epoch: 10/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 10/30 with time: 1380.5813789367676 - validloss: 5779.125\n",
            "Epoch: 11/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 11/30 with time: 1376.387261390686 - validloss: 5461.484375\n",
            "Epoch: 12/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 12/30 with time: 1378.5519616603851 - validloss: 5153.65625\n",
            "Epoch: 13/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 13/30 with time: 1388.6306562423706 - validloss: 5064.625\n",
            "Epoch: 14/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 14/30 with time: 1381.844890832901 - validloss: 4947.3125\n",
            "Epoch: 15/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 15/30 with time: 1367.7164540290833 - validloss: 4658.96875\n",
            "Epoch: 16/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 16/30 with time: 1359.6708161830902 - validloss: 5129.796875\n",
            "Epoch: 17/30\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 epoch 17/30 with time: 1364.178743839264 - validloss: 6201.78125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict after 17 epochs\n",
        "#--> Get model after 15 epoch\n",
        "EMBEDDING_DIM = 168\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "#char\n",
        "embeddingSize = 10\n",
        "hiddenSize = 25\n",
        "charSize = len(char2int)\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "charModel = CharEmbedding(embeddingSize, hiddenSize, charSize)\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                {'params': model.parameters()},\n",
        "                {'params': charModel.parameters(), 'lr': 1e-3}\n",
        "            ], lr=1e-3)\n",
        "\n",
        "model.load_state_dict(torch.load('WordEmbedCharPOS_epoch15.pt'))\n",
        "print(model.eval())\n",
        "charModel.load_state_dict(torch.load('WordEmbedCharPOS1_epoch15.pt'))\n",
        "print(charModel.eval())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgHMFfNiebra",
        "outputId": "b7b376c9-1f8f-487e-b7d2-7438a3e1f982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiLSTM_CRF(\n",
            "  (lstm): LSTM(168, 100, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=200, out_features=22, bias=True)\n",
            ")\n",
            "CharEmbedding(\n",
            "  (embed): Embedding(170, 10)\n",
            "  (BiLSTM): LSTM(10, 25, batch_first=True, bidirectional=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"predict3.txt\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "for index, (sent, embeds, tags, pos, char) in enumerate(testing_data):\n",
        "  embeds = torch.tensor(embeds, dtype=torch.float32)\n",
        "  char_embed = charModel(char)\n",
        "  pos = torch.tensor(pos, dtype=torch.float32)\n",
        "  inputs = torch.cat((embeds,char_embed, pos), 1)\n",
        "  targets = torch.tensor(tags)\n",
        "\n",
        "  _, pred_targets = model(inputs)\n",
        "  pred_tag = [list(tag_to_ix.keys())[list(tag_to_ix.values()).index(tag)] for tag in pred_targets]\n",
        "  true_tag = [list(tag_to_ix.keys())[list(tag_to_ix.values()).index(tag)] for tag in targets]\n",
        "  for word, tags, pred in zip(testing_data[index][0], true_tag, pred_tag):\n",
        "      f.write(\"{} a {} {}\\n\".format(word, tags, pred))"
      ],
      "metadata": {
        "id": "ZwEGaUGAfV6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python conlleval.py < predict3.txt > result3.txt\n",
        "path = '/content/drive/MyDrive/AI/result3.txt'\n",
        "with open(path, 'r') as result:\n",
        "  print(result.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es5hr0hBgPbB",
        "outputId": "7a3d24b7-6957-477f-fd04-de1aff8794e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed 109490 tokens with 14619 phrases; found: 13948 phrases; correct: 12736.\n",
            "accuracy:  85.45%; (non-O)\n",
            "accuracy:  95.71%; precision:  91.31%; recall:  87.12%; FB1:  89.17\n",
            "              AGE: precision:  92.40%; recall:  95.19%; FB1:  93.78  750\n",
            "             DATE: precision:  97.68%; recall:  97.12%; FB1:  97.40  2109\n",
            "           GENDER: precision:  95.14%; recall:  91.51%; FB1:  93.29  555\n",
            "              JOB: precision:  79.52%; recall:  30.00%; FB1:  43.56  83\n",
            "         LOCATION: precision:  89.32%; recall:  88.57%; FB1:  88.94  5346\n",
            "             NAME: precision:  93.98%; recall:  74.73%; FB1:  83.26  299\n",
            "     ORGANIZATION: precision:  77.64%; recall:  70.43%; FB1:  73.86  899\n",
            "       PATIENT_ID: precision:  97.61%; recall:  96.62%; FB1:  97.11  2547\n",
            "SYMPTOM_AND_DISEASE: precision:  83.66%; recall:  67.00%; FB1:  74.40  1138\n",
            "   TRANSPORTATION: precision:  88.74%; recall:  89.14%; FB1:  88.94  222\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "p91ygBk6kvEU",
        "smGFqkdxBGBJ",
        "iNUNpA8YBWG-",
        "2q9B5DO2B7no",
        "kv692Uun9Zm0"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}